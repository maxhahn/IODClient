{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgp\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.generalized_linear_model import GLMResults\n",
    "from statsmodels.genmod.families import family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = dgp.GenericNode('Z', node_restrictions=[dgp.Node])\n",
    "node2 = dgp.GenericNode('X', parents=[node1], node_restrictions=[dgp.Node])\n",
    "node3 = dgp.GenericNode('Y', parents=[node1], node_restrictions=[dgp.CategoricalNode], min_categories=3)\n",
    "nc924 = dgp.NodeCollection('L-M Con. Indep.', [node1, node2, node3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_categorical(_data, y_label, X_labels, betas):\n",
    "    \n",
    "    \n",
    "    data = _data.to_dummies(cs.string(), separator='__cat__')\n",
    "        \n",
    "    results = {}\n",
    "    \n",
    "    #print(f'REGRESSING: {y_label} ~ {X_labels}')\n",
    "    \n",
    "    X = data.to_pandas()[sorted(X_labels)]\n",
    "    X['__const'] = 1\n",
    "    X = X.to_numpy().astype(float)\n",
    "        \n",
    "    models = {}\n",
    "    for cat in betas.keys():\n",
    "        y = data.to_pandas()[cat]\n",
    "        y = y.to_numpy().astype(float)\n",
    "        \n",
    "        glm_model = sm.GLM(y, X, family=family.Binomial())\n",
    "        glm_results = GLMResults(glm_model, betas[cat], normalized_cov_params=None, scale=None)\n",
    "        models[cat] = glm_results\n",
    "        \n",
    "    # Get weights for each sample, depending on its class -> combat dataset imbalance\n",
    "    # class_weights = {}\n",
    "    # for r in self.data.group_by(y_label).agg(pl.len()).rows():\n",
    "    #     class_weights[r[0]] = len(self.data)/((len(betas)+1)*r[1])  \n",
    "    # sample_weights = self.data.with_columns(__sample_weight=pl.col(y_label).replace_strict(class_weights, return_dtype=pl.Float64))['__sample_weight'].to_numpy()\n",
    "        \n",
    "    etas = {c:np.clip(m.predict(which='linear'), -709, 305) for c,m in models.items()}\n",
    "    denom = 1 + sum(np.exp(eta) for eta in etas.values())\n",
    "\n",
    "    mus = {c:np.clip(np.exp(eta)/denom,1e-15,1-1e-15) for c,eta in etas.items()}\n",
    "    dmu_deta = {c:mu*(1-mu) for c,mu in mus.items()}\n",
    "    \n",
    "    \n",
    "    for cat in dmu_deta.keys():\n",
    "        y = data.to_pandas()[cat]\n",
    "        y = y.to_numpy().astype(float)\n",
    "        \n",
    "        z = etas[cat] + (y - mus[cat])/dmu_deta[cat]\n",
    "        \n",
    "        W = np.diag((dmu_deta[cat]**2)/max(np.var(mus[cat]), 1e-15))\n",
    "        \n",
    "        xw = X.T @ W\n",
    "        xwx = xw @ X\n",
    "        xwz = xw @ z\n",
    "        \n",
    "        results[cat] = (xwx, xwz)\n",
    "    \n",
    "    # LLF\n",
    "    def get_cat_index(data, y_label, cat):\n",
    "        cat_val = cat.split('__cat__')[-1]\n",
    "        return data.with_row_index().filter(pl.col(y_label) == cat_val)['index'].to_list()\n",
    "    \n",
    "    def get_ref_cat_index(data, y_label, cats):\n",
    "        cat_vals = [cat.split('__cat__')[-1] for cat in cats]\n",
    "        return data.with_row_index().filter(~pl.col(y_label).is_in(cat_vals))['index'].to_list()\n",
    "    \n",
    "    cat_indexes = {cat: get_cat_index(_data, y_label, cat) for cat in mus.keys()}\n",
    "    \n",
    "    llf = 0 \n",
    "    for cat in cat_indexes.keys():\n",
    "        llf += np.sum(np.log(np.take(mus[cat], cat_indexes[cat])))\n",
    "    llf += np.sum(np.log(np.take(1/denom, get_ref_cat_index(_data, y_label, cat_indexes.keys()))))\n",
    "    \n",
    "    # DEVIANCE + LLF SAT\n",
    "    llf_sat = 0\n",
    "    for cat in cat_indexes.keys():\n",
    "        y = data.to_pandas()[cat]\n",
    "        y = y.to_numpy().astype(float)\n",
    "        \n",
    "        # Only add log for y == 1, since log(0) should be excluded\n",
    "        llf_sat += np.sum(y * np.log(np.clip(y, 1e-10, None)))  # Clip to avoid log(0) issues\n",
    "        \n",
    "    def get_ref_cat_mask(data, y_label, cats):\n",
    "        cat_vals = [cat.split('__cat__')[-1] for cat in cats]\n",
    "        return data.with_columns(__mask=~pl.col(y_label).is_in(cat_vals))['__mask'].cast(pl.Float64).to_numpy()\n",
    "        \n",
    "    # Handle reference category similarly\n",
    "    #y_ref = data.to_pandas()[reference_category]\n",
    "    #y_ref = y_ref.to_numpy().astype(float)\n",
    "    y_ref = get_ref_cat_mask(_data, y_label, cat_indexes.keys())\n",
    "    llf_sat += np.sum(y_ref * np.log(np.clip(y_ref, 1e-10, None)))\n",
    "    \n",
    "    deviance = 2 * (llf_sat - llf)\n",
    "        \n",
    "    return results, llf, deviance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_multionomial_regression(data, y_label, X_labels, debug=True):\n",
    "    last_deviance = None\n",
    "    deviance = 0\n",
    "\n",
    "    categories = [f'{y_label}__cat__{c}' for c in sorted(data[y_label].unique().to_list())]\n",
    "    betas = {c:np.zeros(len(X_labels)+1) for c in categories[1:]}\n",
    "\n",
    "    counter = 1\n",
    "\n",
    "    # CALL FUNC\n",
    "    while True:\n",
    "        if debug and counter == 1 or counter % 10 == 0:\n",
    "            print(f'Running iteration: {counter}')\n",
    "        last_deviance = deviance\n",
    "        results, llf, deviance =_compute_categorical(data, y_label, X_labels, betas)\n",
    "\n",
    "        xwx= {c:results[c][0] for c in betas.keys()}\n",
    "        xwz = {c:results[c][1] for c in betas.keys()}\n",
    "\n",
    "        xwx_inv = {}\n",
    "        for c,xwx in xwx.items():\n",
    "            try:\n",
    "                xwx_inv[c] = np.linalg.inv(xwx)\n",
    "            except np.linalg.LinAlgError:\n",
    "                xwx_inv[c] = np.linalg.pinv(xwx)\n",
    "\n",
    "        new_betas = {cat:xwx_inv[cat] @ xwz[cat] for cat in betas.keys()}\n",
    "        betas = new_betas\n",
    "\n",
    "        # CHECK DEVIANCE\n",
    "        if abs(deviance - last_deviance) / (0.1 + abs(deviance)) < 1e-8:\n",
    "            break\n",
    "        counter += 1\n",
    "\n",
    "    if debug:\n",
    "        print('')\n",
    "        print(f'Converged after {counter} steps')\n",
    "        print(f'LLF: {llf}')\n",
    "        print(f'beta: {betas}')\n",
    "    \n",
    "    return llf, betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial_logistic_regression(data, y_label, X_labels):\n",
    "    # Add a constant (intercept) to the independent variables\n",
    "    _data = data.with_columns(__const=pl.lit(1)).to_pandas()\n",
    "    X = _data[X_labels + ['__const']]\n",
    "    # The dependent variable (must be categorical)\n",
    "    y = _data[y_label]\n",
    "    \n",
    "    # Fit the multinomial logistic regression model\n",
    "    model = sm.MNLogit(y, X)\n",
    "    result = model.fit()\n",
    "    \n",
    "    # Get the log-likelihood function (LLF) and coefficients\n",
    "    llf = result.llf\n",
    "    coefficients = result.params\n",
    "    \n",
    "    return llf, coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌─────┬───────────┬───────────┐\n",
      "│ Y   ┆ X         ┆ Z         │\n",
      "│ --- ┆ ---       ┆ ---       │\n",
      "│ str ┆ f64       ┆ f64       │\n",
      "╞═════╪═══════════╪═══════════╡\n",
      "│ 2   ┆ 0.56404   ┆ 0.54228   │\n",
      "│ 4   ┆ -0.63956  ┆ 0.530321  │\n",
      "│ 3   ┆ 0.445197  ┆ -0.06389  │\n",
      "│ 1   ┆ -0.290108 ┆ 0.856704  │\n",
      "│ 4   ┆ 0.087565  ┆ -0.725127 │\n",
      "└─────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "nc924.reset()\n",
    "data = nc924.get(10000)\n",
    "\n",
    "y_label = 'Y'\n",
    "X_labels = ['X']\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "supersample_cat = '1'\n",
    "data_a = data.filter(pl.col(y_label) == supersample_cat)\n",
    "data_b = data.filter(pl.col(y_label) != supersample_cat)\n",
    "\n",
    "data_b = data_b.sample(len(data_a))\n",
    "data = pl.concat([data_a, data_b])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iteration: 1\n",
      "Running iteration: 10\n",
      "\n",
      "Converged after 15 steps\n",
      "LLF: -13781.206100806756\n",
      "beta: {'Y__cat__2': array([ 0.08472371, -0.11894132]), 'Y__cat__3': array([ 0.13553075, -0.32229342]), 'Y__cat__4': array([ 0.20806508, -0.11688616])}\n"
     ]
    }
   ],
   "source": [
    "llf, coeff = custom_multionomial_regression(data, y_label, X_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.378121\n",
      "         Iterations 4\n"
     ]
    }
   ],
   "source": [
    "llf_mn, coeff_mn = multinomial_logistic_regression(data, y_label, X_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>0</th><th>1</th><th>2</th></tr><tr><td>u32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>0.084724</td><td>0.135531</td><td>0.208065</td></tr><tr><td>1</td><td>-0.118941</td><td>-0.322293</td><td>-0.116886</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 4)\n",
       "┌───────┬───────────┬───────────┬───────────┐\n",
       "│ index ┆ 0         ┆ 1         ┆ 2         │\n",
       "│ ---   ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ u32   ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞═══════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0     ┆ 0.084724  ┆ 0.135531  ┆ 0.208065  │\n",
       "│ 1     ┆ -0.118941 ┆ -0.322293 ┆ -0.116886 │\n",
       "└───────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_cat = int(list(coeff.keys())[0].split('__cat__')[-1])\n",
    "_coeff = {str(int(c.split('__cat__')[-1])-min_cat):l.tolist() for c,l in coeff.items()}\n",
    "coeff_df = pl.from_dict(_coeff).with_row_index()\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>0</th><th>1</th><th>2</th></tr><tr><td>u32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>0.084426</td><td>0.135578</td><td>0.208236</td></tr><tr><td>1</td><td>-0.118977</td><td>-0.322436</td><td>-0.117199</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 4)\n",
       "┌───────┬───────────┬───────────┬───────────┐\n",
       "│ index ┆ 0         ┆ 1         ┆ 2         │\n",
       "│ ---   ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ u32   ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞═══════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0     ┆ 0.084426  ┆ 0.135578  ┆ 0.208236  │\n",
       "│ 1     ┆ -0.118977 ┆ -0.322436 ┆ -0.117199 │\n",
       "└───────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_mn_df = pl.from_pandas(coeff_mn).with_row_index()\n",
    "coeff_mn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promotion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
